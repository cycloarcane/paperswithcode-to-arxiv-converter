# Example Academic Paper Collection

This is an example markdown file showing various ways Papers with Code links might appear in academic documentation.

## Research Papers

### Natural Language Processing

- **Attention Is All You Need**
  **Paper**: [Link](https://arxiv.org/abs/1706.03762)  
  **Summary**: This paper introduces the Transformer architecture, a novel neural network architecture based solely on attention mechanisms.
  **Tags**: #transformer #attention #nlp

- **BERT: Pre-training of Deep Bidirectional Transformers**
  **Paper**: [Link](https://arxiv.org/abs/1810.04805)
  **Summary**: BERT represents a significant advancement in pre-trained language representations.

### Computer Vision

- **ResNet Paper**
  See the original ResNet paper here: https://arxiv.org/abs/1512.03385
  This was a breakthrough in deep learning for computer vision.

### Mixed Format Examples

Some papers might be referenced inline like this [Transformer paper](https://arxiv.org/abs/1706.03762) or in parentheses (https://arxiv.org/abs/1810.04805).

### Edge Cases

- Papers with cs.paperswithcode.com domain: https://arxiv.org/abs/2024.example
- Papers with query parameters: https://arxiv.org/abs/2024.example2
- Papers with fragments: https://arxiv.org/abs/2024.example3

## References

1. Vaswani, A., et al. "Attention is all you need." [Link](https://arxiv.org/abs/1706.03762)
2. Devlin, J., et al. "BERT: Pre-training of Deep Bidirectional Transformers" [Link](https://arxiv.org/abs/1810.04805)